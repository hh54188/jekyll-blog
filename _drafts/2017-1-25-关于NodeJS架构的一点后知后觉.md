## 前言

上周有幸和淘宝前端团队的七念老师做了一些NodeJS方面上的交流（实际情况其实是他电话面试了我……），我们主要聊到了我参与维护的一个线上NodeJS服务，关于它的现状和当下的不足。他向我提出的一些问题带给了我很大启发，尽管我回答的不好。简单来说问题就是，对于你意识到的这些不足，你将尝试怎样去改进它们？再发散一些的说，如果给你一个机会来重新设计这个系统服务，你将如何做？相比现在有什么的改进？

为什么说这些问题对我产生了启发，是因为这些问题是我不曾考虑过的。或者说考虑过，但没有这么严肃的考虑过。这里的“严肃”指的是具体到企业级，线上，细节等方面。而我在尝试回答这些问题，在寻找答案的过程中又发现一片新的天地，收获了不少新的知识。

这篇文章与以往的文章不同，并不是阐述某一个问题的最佳解决方案，甚至不会落实到具体的代码上。而是分享在探寻答案过程中收获的心得、留下的困惑还有一点个人的经验。至于这些能否拿来回答最初的那些问题我没有十足的把握，能，但不是最佳答案。因为后端架构实在一个很有深度的话题，也是一个极其成熟的技术方向。即使有了理论方面的积累，面对千变万化的业务需求难免还是灵活的对方案进行改进，而无论是理论还是实践经验都是我欠缺的。

这段话本来应该是写在结尾的话感觉顺嘴也就挂在了开头，最后想说，还是老祖宗说的好：纸上得来终觉浅，绝知此事要躬行。

## 正文

一个怎样的后端服务才能算得上优秀？或者放低一点说合格？再把这个问题翻译翻译，优秀或者合格的标准是什么？

假设现在需要你用NodeJS搭建一个http服务，我猜测你会借助express框架用不到10行的代码完成这项工作。不能说这么做是错的，但这样简易的程序是脆弱的：一旦部署上线之后，可能瞬间就被大量涌入的请求击垮，更不要提各种潜在的漏洞危险。退一步说，即使线上程序经过了这一关考验，如果你要更新程序怎么办？不得不让用户中断访问一段时间？

在我看来，后端服务务必要满足两条特性：

- 能容错（fault tolerant）
- 可扩展（scalability）

当然还有一些其他特性也很重要，比如程序要健壮，接口设计要友好，程序修改起来要灵活等等。但容错性和拓展性才是正常运行的基本保障，至少保证了你的服务是可用的，永远是可用的。而无论实现服务的代码如何优雅，它都是为业务服务的，一旦用户无法访问你的服务了，再优美的代码也无济于事。所以接下来的问题就是，我们后端程序的架构如何的设计以保证满足这两条特性。

以下的部分内容和图片参考自图书：Node.js design patterns。如有雷同，不是巧合。

首先我们说说拓展性（scalability）。

按照书中的说法，拓展性划分为三类，如下图所示：

![type of scalability](./images/something-about-nodejs-architecture/type-of-scale.png)

- X轴方向：纯粹的对服务实例进行拓展，例如为了响应更多的请求
- y轴方向：为服务添加新的功能，功能性拓展
- z轴方向：按照业务数据对服务进行拓展（这里没搞懂，不知道这么说是否准确）

而通常实际的拓展过程中多维度是同时进行的，例如增添了新的功能也就意味着有跟多的流量进入，也就是意味着需要增加新的服务实例。

### 实例拓展

我们先谈第一类X轴拓展，增加服务的实例。增加服务实例也分为两类，横向拓展（horizontal scaling）和纵向拓展（vertical scaling），横向表示利用更多的机器，纵向表示在同一台机器上挖掘它的潜力。但在实际操作的过程中，横向和纵向两者解决问题的思路的差异并不大。

从小到大，先说纵向拓展。

我们都知道NodeJS程序通常是以单进程形式运行，单线程的NodeJS程序也只有1GB内存的实用权限（在64位机器上最大的内存权限扩大到1.7GB）。而目前绝大部分线上机器的CPU都是多核的，并且至少16GB起，如此以来Node程序便无法充分发挥机器的潜力。同时NodeJS自己也意识到了这一点，所以它允许程序创建多个子进程用于运行多个实例。

具体技术细节涉及到Cluster模块，详情可以查看NodeJS相关文档: https://nodejs.org/api/cluster.html

下图就是对以上所说原理的图解：

![cluster](./images/something-about-nodejs-architecture/cluster.png)

简单来说，首先我们有一个主进程master，但master主进程并不实际的处理业务逻辑，但除了业务逻辑以外事情它都做：一方面它是一个manager，它负责启动子进程，管理子进程（如果子进程挂了要及时重启），另一方面它同时扮演router的角色，所以对该程序的访问请求首先到达主进程master，再由主进程分配请求给子进程worker。而子进程才负责处理业务逻辑。

在这个机制下有两条细节需要我们定夺如何处理。

如何把外界的请求平均的分配给不同的worker处理？这里的平均不是指数量上的平均，而是既不能让某个子进程太闲，也不能让某个子进程太忙，保证它们始终处于工作的状态即可。这也是我们常说的负载均衡（load-balancing）。
默认情况下Cluster模块采用的是round robin负载均衡算法，说白了就是依次按顺序把请求派给列表上的子进程，派到结尾之后又重头开始。

这个算法只能保证每个子进程收到的请求个数是平均的，和随机算法类似。但如果某个子进程遇到问题，处理变得迟缓了，而后续的请求又源源不断的分配过来，那么这个子进程的压力就大了，这就略显不公了。除此之外我们还要考虑到超时，重做等机制的建立。所以主进程master作为路由时不仅仅是转发请求，还要能聪明的转发请求。

另一个问题是状态共享问题，假如某个用户第一次访问该服务时是分配给了线程A上的实例A处理，并且用户在这个实例上进行了登陆，而没有过几秒钟之后当用户第二次访问时分配给了线程B上的实例B处理，如果此时用户在A上的登陆状态没有共享给其他实例的话，那么用户不得不重新登陆一次，这样是无法接受的。如下图所示

![session-share-problem](./images/something-about-nodejs-architecture/session-share-problem.png)

这个问题的解决办法是把状态进行共享，如下图所示：

![session-share-solution01](./images/something-about-nodejs-architecture/session-share-solution01.png)

也可以新增一个模块用于记录用户第一次访问的实例，并在之后当用户访问服务时始终访问该实例

![session-share-solution02](./images/something-about-nodejs-architecture/session-share-solution02.png)

这个思路不仅适用于纵向拓展，还适用于横向拓展。当单台机器已经无法满足你需求的时候，你可以把单实例子进程的概念拓展为单台机器：我们将在多台机器上部署多个进行实例，用户的访问请求也并非直接到达它们，而是先到达前方的代理机器，它也是负责负载均衡的机器，负责将请求转发给部署了应用实例的机器。这样的模式我们也通常称为反向代理模式，如下图所示：

![reverse-proxy](./images/something-about-nodejs-architecture/reverse-proxy.png)

我们仍然能对这个模式持续改进，例如动态的启动或者关闭机器上的实例用于节省资源，甚至想办法移除复杂平衡这一环节用于提高通讯的效率。在这里就不延伸开了去了，具体可以参考Node.js design patterns这本书中的内容。

**最后在这里要说一件很重要的事情**。上面说的负载平衡也好，反向代理也好，都不是新的技术。相反，都是非常非常成熟，有着相当多经验积累的技术。然而为什么我们接触起来却感觉如此的新鲜和陌生？我想原因大概是NodeJS程序员大多是由前端工程师转化而来，而大家此前都只专注于前端代码而很少接触后端知识。然而如果你从入行开始就是一个Java程序员或者运维工程师，相信你对这一切早就耳熟能详并且手到擒来。

几年前看到过一篇文章，（很可惜现在找不到了，如果有哪位同学知道篇文章的麻烦告知一下谢谢），记录的是一位技术人员针对网站访问量增大而做的一系列技术改进。文章的后半部分我记不得了，但是前半部分改进的思路和遇到的问题和我们是一样的：增加实例机器和解决session共享问题。我想说的是，虽然NodeJS是新技术，但是我们解决问题的思路和方案可以来自传统软件行业，并且它们在这方面比我们有经验的多。所以我们在学习NodeJS，在寻找一些问题的解决方案时，不要局限于NodeJS本身，而是应该开阔眼界，跨语言包容的去汲取知识。

### 功能拓展

你也许会问新增功能有什么难点？每个程序员的日常就是不断的进行功能迭代。在这里我们希望解决一个问题，就是既然我们无法保证功能不会出错，那我们有没有办法保证当一个功能出错之后不会影响整个程序的正常运行？这也是我们所说的容错性。

道理大家都懂，我们都明白程序需要容错，所以try/catch是从编码上解决这个问题。但问题是try/catch不是万能的，大家也都知道万无一失的程序是不存在的，所以我们要换个思路解决这个问题，我们允许程序出错，但是要及时把错误隔离，并且不再影响程序的运行。
